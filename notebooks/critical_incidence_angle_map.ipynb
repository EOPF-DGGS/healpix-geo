{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numba\n",
    "import numpy as np\n",
    "import rasterio\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "# Lazy load the 90m DEM ZARR file and select a sub-region\n",
    "\n",
    "The 90m DEM used here is available at:\n",
    "https://common.s3.sbg.perf.cloud.ovh.net/adf.html\n",
    "under the filename: S00__ADF_DEM90_20000101T000000_21000101T000000_20240605T132601.zarr.zip\n",
    "\n",
    "Only the ‘height_50S_50N‘ region is used in this notebook, it represents 35GB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the .zarr folder as a dataset\n",
    "ds = xr.open_zarr(\n",
    "    \"../../DEM/S00__ADF_DEM90_20000101T000000_21000101T000000_20240605T132601.zarr\",\n",
    "    consolidated=True,\n",
    ")\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_min, lat_max = 30, 50\n",
    "lon_min, lon_max = -10, 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "subsampling = 100\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.imshow(\n",
    "    ds.sel(\n",
    "        latitude=slice(324000 * (lat_max / 90), 324000 * (lat_min / 90), subsampling),\n",
    "        longitude_00_50=slice(\n",
    "            648000 * (lon_min / 180), 648000 * (lon_max / 180), subsampling\n",
    "        ),\n",
    "    )[\"height_50S_50N\"].values[:-1, :-1],\n",
    "    cmap=\"OrRd\",\n",
    ")\n",
    "plt.axis(\"off\")\n",
    "plt.title(\n",
    "    r\"DEM GLO90m - lat$\\in [{:}°, {:}°]$   lon$\\in[{:}°, {:}°]$\".format(\n",
    "        lat_min, lat_max, lon_min, lon_max\n",
    "    ),\n",
    "    fontsize=20,\n",
    ")\n",
    "cbar = plt.colorbar()\n",
    "cbar.set_label(\"elevation (m)\", rotation=270, labelpad=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "# Compute the associated max incidence map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## Define some functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cotan_deg(epsilon):\n",
    "    return 1 / np.tan(np.deg2rad(epsilon))\n",
    "\n",
    "\n",
    "def get_radius_from_max_incidence_deg(max_incidence_deg, max_elevation_delta):\n",
    "    assert max_elevation_delta >= 0\n",
    "    return np.tan(np.deg2rad(max_incidence_deg)) * max_elevation_delta\n",
    "\n",
    "\n",
    "def slope_to_incidence_deg(slope):\n",
    "    return np.rad2deg(np.pi / 2 - np.arctan(slope))\n",
    "\n",
    "\n",
    "def get_distance_kernel(radius, pixel_size_lat, pixel_size_lon):\n",
    "    radius_pix_lat = np.int64(\n",
    "        1 + radius / pixel_size_lat\n",
    "    )  # 1 + for safety reasons if elevation_delta=0\n",
    "    radius_pix_lon = np.int64(\n",
    "        1 + radius / pixel_size_lon\n",
    "    )  # 1 + for safety reasons if elevation_delta=0\n",
    "    distance_kernel = np.sqrt(\n",
    "        np.sum(\n",
    "            np.asarray(\n",
    "                np.meshgrid(\n",
    "                    pixel_size_lon * np.arange(-radius_pix_lon, radius_pix_lon + 1, 1),\n",
    "                    pixel_size_lat * np.arange(-radius_pix_lat, radius_pix_lat + 1, 1),\n",
    "                )\n",
    "            )\n",
    "            ** 2,\n",
    "            axis=0,\n",
    "        )\n",
    "    )\n",
    "    distance_kernel[radius_pix_lat, radius_pix_lon] = (\n",
    "        np.inf\n",
    "    )  # fine because later we compute 0 / inf = 0 -> central point will give a slope of 0.\n",
    "    return distance_kernel\n",
    "\n",
    "\n",
    "@numba.njit(parallel=True)\n",
    "def compute_critical_incidence_numba(\n",
    "    elevation, distance_kernel, borders=None, verbose=False\n",
    "):\n",
    "    radius_pix_lat = distance_kernel.shape[0] // 2\n",
    "    radius_pix_lon = distance_kernel.shape[1] // 2\n",
    "\n",
    "    if borders is not None:\n",
    "        assert (\n",
    "            borders.shape[0] - elevation.shape[0]\n",
    "            == borders.shape[1] - elevation.shape[1]\n",
    "        )\n",
    "        assert (borders.shape[0] - elevation.shape[0]) % 2 == 0\n",
    "        shift = (borders.shape[0] - elevation.shape[0]) // 2\n",
    "        assert max(radius_pix_lat, radius_pix_lon) < shift\n",
    "\n",
    "    critical_incidence = np.nan * np.ones(elevation.shape)\n",
    "\n",
    "    if borders is None:\n",
    "        for row in numba.prange(elevation.shape[0]):\n",
    "            print(row, elevation.shape[0]) if row % 100 == 0 and verbose else None\n",
    "            for col in range(elevation.shape[1]):\n",
    "                critical_incidence[row, col] = np.rad2deg(\n",
    "                    np.pi / 2\n",
    "                    - np.arctan(\n",
    "                        np.nanmax(\n",
    "                            (\n",
    "                                elevation[\n",
    "                                    max(row - radius_pix_lat, 0) : min(\n",
    "                                        row + radius_pix_lat + 1, elevation.shape[0]\n",
    "                                    ),\n",
    "                                    max(col - radius_pix_lon, 0) : min(\n",
    "                                        col + radius_pix_lon + 1, elevation.shape[1]\n",
    "                                    ),\n",
    "                                ]\n",
    "                                - elevation[row, col]\n",
    "                            )\n",
    "                            / distance_kernel[\n",
    "                                max(row - radius_pix_lat, 0)\n",
    "                                - row\n",
    "                                + radius_pix_lat : min(\n",
    "                                    row + radius_pix_lat + 1, elevation.shape[0]\n",
    "                                )\n",
    "                                - row\n",
    "                                + radius_pix_lat,\n",
    "                                max(col - radius_pix_lon, 0)\n",
    "                                - col\n",
    "                                + radius_pix_lon : min(\n",
    "                                    col + radius_pix_lon + 1, elevation.shape[1]\n",
    "                                )\n",
    "                                - col\n",
    "                                + radius_pix_lon,\n",
    "                            ]\n",
    "                        )\n",
    "                    )\n",
    "                )\n",
    "    else:\n",
    "        for row in numba.prange(elevation.shape[0]):\n",
    "            print(row, elevation.shape[0]) if row % 100 == 0 and verbose else None\n",
    "            for col in range(elevation.shape[1]):\n",
    "                critical_incidence[row, col] = np.rad2deg(\n",
    "                    np.pi / 2\n",
    "                    - np.arctan(\n",
    "                        np.nanmax(\n",
    "                            (\n",
    "                                borders[\n",
    "                                    row\n",
    "                                    - radius_pix_lat\n",
    "                                    + shift : row\n",
    "                                    + radius_pix_lat\n",
    "                                    + 1\n",
    "                                    + shift,\n",
    "                                    col\n",
    "                                    - radius_pix_lon\n",
    "                                    + shift : col\n",
    "                                    + radius_pix_lon\n",
    "                                    + 1\n",
    "                                    + shift,\n",
    "                                ]\n",
    "                                - elevation[row, col]\n",
    "                            )\n",
    "                            / distance_kernel\n",
    "                        )\n",
    "                    )\n",
    "                )\n",
    "\n",
    "    return critical_incidence\n",
    "\n",
    "\n",
    "def get_region_name(region, max_incidence_deg):\n",
    "    return \"S{:}_N{:}_O{:}_E{:}_imax{:}\".format(*region, max_incidence_deg)\n",
    "\n",
    "\n",
    "def compute_region(region, pixel_size_lat=92.6, max_incidence_deg=70, verbose=2):  # m\n",
    "    lat_min, lat_max, lon_min, lon_max = region\n",
    "    subset = ds.sel(\n",
    "        latitude=slice(324000 * (lat_max / 90), 324000 * (lat_min / 90)),\n",
    "        longitude_00_50=slice(648000 * (lon_min / 180), 648000 * (lon_max / 180)),\n",
    "    )\n",
    "    subset_larger = ds.sel(\n",
    "        latitude=slice(\n",
    "            324000 * ((lat_max + 0.5) / 90), 324000 * ((lat_min - 0.5) / 90)\n",
    "        ),\n",
    "        longitude_00_50=slice(\n",
    "            648000 * ((lon_min - 0.5) / 180), 648000 * ((lon_max + 0.5) / 180)\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    elevation = subset[\"height_50S_50N\"].values[:-1, :-1]\n",
    "    elevation_larger = subset_larger[\"height_50S_50N\"].values[:-1, :-1]\n",
    "    if verbose > 0 and np.all(np.isnan(elevation)):\n",
    "        print(\"WARNING EMPTY REGION\")\n",
    "    assert not np.all(np.isnan(elevation))\n",
    "\n",
    "    pixel_size_lon = np.cos(np.deg2rad(0.5 * (lat_max + lat_min))) * pixel_size_lat  # m\n",
    "\n",
    "    radius = get_radius_from_max_incidence_deg(\n",
    "        max_incidence_deg=max_incidence_deg,\n",
    "        max_elevation_delta=np.nanmax(elevation) - np.nanmin(elevation),\n",
    "    )  # m\n",
    "\n",
    "    distance_kernel = get_distance_kernel(\n",
    "        radius=radius, pixel_size_lat=pixel_size_lat, pixel_size_lon=pixel_size_lon\n",
    "    )\n",
    "\n",
    "    if verbose >= 2:\n",
    "        plt.imshow(elevation[::10, ::10]), plt.colorbar(), plt.show()\n",
    "\n",
    "    if verbose >= 1:\n",
    "        print(\"    Elevation Shape:\", elevation.shape)\n",
    "        print(\"    Min elevation:\", np.nanmin(elevation))\n",
    "        print(\"    Max elevation:\", np.nanmax(elevation))\n",
    "        print(\"    Radius (km): \", radius * 1e-3)\n",
    "        print(\"    Kernel shape (lat, lon): \", distance_kernel.shape)\n",
    "\n",
    "    start = time.perf_counter()\n",
    "    critical_incidence = compute_critical_incidence_numba(\n",
    "        elevation,\n",
    "        distance_kernel=distance_kernel,\n",
    "        borders=elevation_larger,\n",
    "        verbose=True if verbose >= 2 else False,\n",
    "    )\n",
    "    end = time.perf_counter()\n",
    "    if verbose >= 1:\n",
    "        print(f\"Elapsed time: {end - start:.2f} seconds\")\n",
    "\n",
    "    outputfile = \"../../DEM/GLO90_critical_incidence_maps/{:}.npy\".format(\n",
    "        get_region_name(region, max_incidence_deg)\n",
    "    )\n",
    "    np.save(outputfile, critical_incidence.astype(np.float16), allow_pickle=True)\n",
    "\n",
    "    if verbose >= 1:\n",
    "        print(f\"Saved to: \", outputfile)\n",
    "\n",
    "\n",
    "try:\n",
    "    os.mkdir(\"../../DEM/GLO90_critical_incidence_maps\")\n",
    "except FileExistsError:\n",
    "    pass\n",
    "\n",
    "print(\n",
    "    \"Critical incidence maps will be saved at ../../DEM/GLO90_critical_incidence_maps/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## Compute the maps chunk by chunk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = []\n",
    "for lat in range(lat_min, lat_max):\n",
    "    for lon in range(lon_min, lon_max):\n",
    "        regions.append((lat, lat + 1, lon, lon + 1))\n",
    "done = []\n",
    "fails = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the maximum incidence in degrees\n",
    "# a pixel having a true critical incidence value larger than max_incidence_deg will be computed with a cropped neighboring kernel\n",
    "# therefore the computed critical incidence for such pixel cannot be fully trusted\n",
    "# but we know for sure that the true critical incidence for such pixel remains larger than max_incidence_deg\n",
    "max_incidence_deg = 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "for region in regions:\n",
    "    print(\n",
    "        \"\\n\\n=====================================\\n=====================================\\nStarting region: \",\n",
    "        region,\n",
    "    )\n",
    "    if not region in done or region in fails:\n",
    "        try:\n",
    "            compute_region(\n",
    "                region,\n",
    "                pixel_size_lat=92.6,  # m\n",
    "                max_incidence_deg=max_incidence_deg,\n",
    "                verbose=1,\n",
    "            )\n",
    "            done.append(region)\n",
    "            print(\"************* Done region: \", region)\n",
    "        except:\n",
    "            fails.append(region)\n",
    "            print(\"xxxxxxxxxxxxx Failed region: \", region)\n",
    "    else:\n",
    "        print(\"-------------- Skipping region: \", region)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## Loading results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "loading_subsampling = 1\n",
    "critical_incidence = np.nan * np.ones(\n",
    "    (\n",
    "        1200 * (lat_max - lat_min) // loading_subsampling,\n",
    "        1200 * (lon_max - lon_min) // loading_subsampling,\n",
    "    ),\n",
    "    dtype=np.float16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "for lat in range(lat_min, lat_max):\n",
    "    for lon in range(lon_min, lon_max):\n",
    "        region = (lat, lat + 1, lon, lon + 1)\n",
    "        try:\n",
    "            critical_incidence[\n",
    "                1200\n",
    "                * (lat_max - lat - 1)\n",
    "                // loading_subsampling : 1200\n",
    "                * (lat_max - lat)\n",
    "                // loading_subsampling,\n",
    "                1200\n",
    "                * (lon - lon_min)\n",
    "                // loading_subsampling : 1200\n",
    "                * (lon + 1 - lon_min)\n",
    "                // loading_subsampling,\n",
    "            ] = np.load(\n",
    "                \"../../DEM/GLO90_critical_incidence_maps/{:}.npy\".format(\n",
    "                    get_region_name(region, max_incidence_deg)\n",
    "                )\n",
    "            )[\n",
    "                ::loading_subsampling, ::loading_subsampling\n",
    "            ]\n",
    "            # print(\"Loaded region: \", region)\n",
    "        except:\n",
    "            # print(\"xxxxxxxxxxxxxxxx Failed region: \", region)\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Making sure that critical incidences above max_incidence_deg are not misunderstood as explained above\n",
    "critical_incidence[critical_incidence > max_incidence_deg] = max_incidence_deg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_subsampling = 10 // loading_subsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 7))\n",
    "plt.imshow(\n",
    "    critical_incidence[::plot_subsampling, ::plot_subsampling], vmin=40, cmap=\"bwr_r\"\n",
    ")\n",
    "plt.axis(\"off\")\n",
    "plt.title(\n",
    "    \"Critical incidence angle map\\n(computed with incid. max={:}°)\".format(\n",
    "        max_incidence_deg\n",
    "    ),\n",
    "    fontsize=20,\n",
    ")\n",
    "plt.colorbar(extend=\"both\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 7))\n",
    "plt.imshow(\n",
    "    critical_incidence[::plot_subsampling, ::plot_subsampling] <= 55, cmap=\"gray_r\"\n",
    ")\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Problematic points (critical incidence < 55°)\", fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_subsampling = plot_subsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import PercentFormatter\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.grid(True, which=\"major\")\n",
    "plt.hist(\n",
    "    critical_incidence[::hist_subsampling, ::hist_subsampling][\n",
    "        ~np.isnan(critical_incidence[::hist_subsampling, ::hist_subsampling])\n",
    "    ].flatten(),\n",
    "    cumulative=True,\n",
    "    bins=500,\n",
    "    density=True,\n",
    ")\n",
    "plt.xlim(25, max_incidence_deg), plt.ylim(0, 0.1)\n",
    "plt.gca().yaxis.set_major_formatter(PercentFormatter(1))\n",
    "plt.xlabel(\"critical incidence threshold (°)\")\n",
    "plt.ylabel(\"proportion of problematic points\")\n",
    "plt.title(\"Proportion of problematic points depending on the incidence threshold\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "refine_hist_subsampling = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "plt.hist(\n",
    "    critical_incidence[::refine_hist_subsampling, ::refine_hist_subsampling][\n",
    "        ~np.isnan(\n",
    "            critical_incidence[::refine_hist_subsampling, ::refine_hist_subsampling]\n",
    "        )\n",
    "    ].flatten(),\n",
    "    cumulative=True,\n",
    "    bins=500,\n",
    "    density=True,\n",
    "    log=True,\n",
    ")\n",
    "plt.grid(True)\n",
    "plt.xlim(0, max_incidence_deg), plt.ylim(1e-9, 1e-1)\n",
    "\n",
    "plt.xlabel(\"critical incidence threshold (°)\")\n",
    "plt.ylabel(\"proportion of problematic points\")\n",
    "plt.title(\"Proportion of problematic points depending on the incidence threshold\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
